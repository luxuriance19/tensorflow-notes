{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimators 封装在下列actions当中：\n",
    "<ul type='disc'>\n",
    "    <li>training</li>\n",
    "    <li>evaluation</li>\n",
    "    <li>prediction</li>\n",
    "    <li>export for serving</li>\n",
    "</ul>\n",
    "<font size=\"2\" color=\"grey\"> 所有的Estimators都基于tf.estimator.Estimators 类(tf.contrib.learn.Estimator)已经被废弃，不应该继续使用</font>   \n",
    "\n",
    "<b> Estimator 优势：</b>\n",
    "\n",
    "<ul>\n",
    "    <li>使用Estimator_based模型，不需要在不同的平台上修改代码</li>\n",
    "    <li>Estimators simplify sharing implementations between model developers</li>\n",
    "    <li>You can develop a state of the art model with high-level intuitive code, In short, it is generally much easier to create models with Estimators than with the low-level TensorFlow APIs.</li>\n",
    "    <li>Estimators 简历在tf.layers上面，可以简单的被自定义</li>\n",
    "    <li>Estimators可以自动的创建Graph</li>\n",
    "    <li>Estimators可以提供safe distributed training loop that controls how and when to:</li>\n",
    "    <ul>\n",
    "    <li>构建图形</li>\n",
    "    <li>初始化变量</li>\n",
    "    <li> start queues</li>\n",
    "    <li>处理已成</li>\n",
    "    <li>create checkpoint files and recover from failures</li>\n",
    "    <li>为Tensorboard保存summaries</li>\n",
    "    </ul>\n",
    "    </ul>  \n",
    "当写一个具有Estimators的应用是，you must separate the data input pipeline from the model.这样做可便于实验数据的替换。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-made Estimators\n",
    "pre-made Estimators可以创建和管理Graph和Session对象。   \n",
    "Furthermore, pre-made Estimators let you experiment with different model architectures by making only minimal code changes. DNNClassifier, for example, is a pre-made Estimator class that trains classification models through dense, feed-forward neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>tf.estimator.LinearClassifier:</b> Constructs a linear classification model.\n",
    "<b>tf.estimator.LinearRegressor:</b> Constructs a linear regression model.  \n",
    "<b>tf.estimator.DNNClassifier:</b> Construct a neural network classification model.  \n",
    "<b>tf.estimator.DNNRegressor:</b> Construct a neural network regression model.  \n",
    "<b>tf.estimator.DNNLinearCombinedClassifier:</b> Construct a neural network and linear combined classification model.  \n",
    "<b>tf.estimator.DNNLinearCombinedRegressor:</b> Construct a neural network and linear combined regression model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of a pre-made Estimators program\n",
    "1.<b> 写一个或者多个dataset导入函数。</b>  \n",
    "input_fn\n",
    "<p> 每个dataset导入函数返回两个对象：\n",
    "    <ul>\n",
    "        <li> 字典：keys：特征名称，values：Tensor(or sparse Tensros)对应相应的特征。</li>\n",
    "        <li> Tensor: 包含一个或者多个标签</li>\n",
    "    </ul>\n",
    "</p>\n",
    "<p>\n",
    "    input function(input_fn)的主题包含了input data预处理过程，必须要返回两个值包含处理过的feature和label(用于传递给模型)：（函数的skeleton见上面)my_input_fn):  \n",
    "    <ul>\n",
    "        <li><b>feature_cols: </b>dict: 包含key/value成对对应到feature columns names和包含相应特征的Tensor(Sparse Tensor)</li>\n",
    "        <li><b>labels: </b>a Tensor包含目标值(label)，即模型的预测值</li>\n",
    "    </ul>\n",
    "</p>\n",
    "<p>\n",
    "    如果feature/label data使用python array存储在pandas dataframe或者numpy array中，可以用以下方法来构建input_fn:详细例子如下\n",
    "</p>\n",
    "<p>\n",
    "    对于sparse,categorical data(大部分值为0),那么input_fn可以改为填充一个SparseTensor，可以通过三个参数实例化：\n",
    "    <ul>\n",
    "        <li><b>dense_shape: </b>  \n",
    "            the shape of tensor.list类型，每一个元素代表当前的维度，e.g.dense_shape=[3,6],[2,3,4],[9]分别代表二维，三维，一维的tensor\n",
    "        </li>\n",
    "        <li><b>indices: </b>  \n",
    "            知名非零值出现的位置，list类型。index以0开始，即[0,0]表示第一行第一列，indices=[[1,3],[2,4]]代表[1,3],[2,4]的index处不为零\n",
    "        </li>\n",
    "        <li><b>values: </b>  \n",
    "            一维tensor，第i个值表示indices中的第i个元素填充的值\n",
    "        </li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#e.g.: \n",
    "def input_fn(dataset):\n",
    "    ...# manipulate dataset, extracting feature names and the label\n",
    "    return feature_dict,label\n",
    "\n",
    "def my_input_fn():\n",
    "    # Preprocess your data here...\n",
    "\n",
    "    # ...then return 1) a mapping of feature columns to Tensors with\n",
    "    # the corresponding feature data, and 2) a Tensor containing labels\n",
    "    return feature_cols, labels\n",
    "\n",
    "import numpy as np\n",
    "# numpy input_fn.\n",
    "my_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": np.array(x_data)},\n",
    "    y=np.array(y_data),\n",
    "    ...)\n",
    "\n",
    "import pandas as pd\n",
    "# pandas input_fn.\n",
    "my_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=pd.DataFrame({\"x\": x_data}),\n",
    "    y=pd.Series(y_data),\n",
    "    ...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 5]\n"
     ]
    }
   ],
   "source": [
    "sparse_tensor = tf.SparseTensor(indices=[[0,1], [2,4]],\n",
    "                                values=[6, 0.5],\n",
    "                                dense_shape=[3, 5])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(sparse_tensor).dense_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.<b> 定义特征columns。</b>每一个tf.feature_column定义(identifies)一个特征名字，他的类型和任何的预处理（input pre-processing)  \n",
    "<p>这个例子中创建了三个特征columns包含integer或者是float-point数据\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define three numeric feature columns\n",
    "population = tf.feature_column.numeric_column('population')\n",
    "crime_rate = tf.feature_column.numeric_column('crime_rate')\n",
    "median_education = tf.feature_column.numeric_column('median_edcation',\n",
    "                                                     normalizer_fn='lambda x:x-global_education_mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.<b> 实例化相关的pre-made Estimator。</b>\n",
    "<p>这个例子中实例化pre-made Estimator为LinearClassifier\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an estimator, passing the feature columns.\n",
    "estimator = tf.estimator.Estimator.LinearClassifier(\n",
    "    feature_columns=[population,crime_rate,median_education],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.<b> Call a training, evaluation, or inference method。</b>\n",
    "<p>所有的Estimator都提供一个train模型\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_training_set is the function created in Step 1\n",
    "estimator.train(input_fn=my_training_set,steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits of pre-made Estimators\n",
    "Pre-made Estimators encode best practices, providing the following benefits:  \n",
    "<ul>\n",
    "    <li>Best practices for determining where different parts of the computational graph should run, implementing strategies on a single machine or on a cluster.</li>\n",
    "    <li>Best practices for event (summary) writing and universally useful summaries.</li>\n",
    "</ul>\n",
    "如果不适用pre-made Estimators,那么需要自行实践preceding features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pre-made Estimator 实例：DNNclassifier，实行dense，feed-forward NN\n",
    "\n",
    "categorical_feature_a = categorical_column_with_hash_bucket(...)\n",
    "categorical_feature_b = categorical_column_with_hash_bucket(...)\n",
    "\n",
    "categorical_feature_a_emb = embedding_column(\n",
    "    categorical_column=categorical_feature_a, ...)\n",
    "categorical_feature_b_emb = embedding_column(\n",
    "    categorical_column=categorical_feature_b, ...)\n",
    "\n",
    "estimator = DNNClassifier(\n",
    "    feature_columns=[categorical_feature_a_emb, categorical_feature_b_emb],\n",
    "    hidden_units=[1024, 512, 256])\n",
    "\n",
    "# Or estimator using the ProximalAdagradOptimizer optimizer with\n",
    "# regularization.\n",
    "estimator = DNNClassifier(\n",
    "    feature_columns=[categorical_feature_a_emb, categorical_feature_b_emb],\n",
    "    hidden_units=[1024, 512, 256],\n",
    "    optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "      learning_rate=0.1,\n",
    "      l1_regularization_strength=0.001\n",
    "    ))\n",
    "\n",
    "# Input builders\n",
    "def input_fn_train: # returns x, y\n",
    "    pass\n",
    "    #e.g.  \n",
    "     return tf.estimator.inputs.pandas_input_fn(\n",
    "      x=pd.DataFrame({k: data_set[k].values for k in FEATURES}),\n",
    "      y = pd.Series(data_set[LABEL].values),\n",
    "      num_epochs=num_epochs,\n",
    "      shuffle=shuffle)\n",
    "estimator.train(input_fn=input_fn_train, steps=100)\n",
    "\n",
    "def input_fn_eval: # returns x, y\n",
    "    pass\n",
    "metrics = estimator.evaluate(input_fn=input_fn_eval, steps=10)\n",
    "def input_fn_predict: # returns x, None\n",
    "    pass\n",
    "predictions = estimator.predict(input_fn=input_fn_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Estimators\n",
    "每一个Estimator的核心（不管是pre-made还是custom）都是model function，\n",
    "是一个建立training, evaluation, 和prediction的方法。  \n",
    "当用 pre-made Estimator的时候，别人已经implemented the model function。\n",
    "在custom Estimator的时候，必须要自己写一个方程  \n",
    "步骤：\n",
    "<ul>\n",
    "    <li>Instantiate an Estimator</li>\n",
    "    <li>Construct a custom model function</li>\n",
    "    <li>Configure a neural network using tf.feature_column and tf.layers</li>\n",
    "    <li>Choose an appropriate loss function from tf.losses</li>\n",
    "    <li>Define a training op for your model</li>\n",
    "    <li>Generate and return predictions</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn = tf.estimator.Estimator(model_fn=model_fn, params=model_params)\n",
    "<ul>\n",
    "    <li><b>model_fn:</b> A function object that contains all the aforementioned logic to support training, evaluation, and prediction. You are responsible for implementing that functionality. The next section, Constructing the model_fn covers creating a model function in detail.</li>\n",
    "\n",
    "<li><b>params:</b> An optional dict of hyperparameters (e.g., learning rate, dropout) that will be passed into the model_fn.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "# Import urllib\n",
    "from six.moves import urllib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "FLAGS = None\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_download(train_data, test_data, predict_data):\n",
    "    \"\"\"Maybe downloads training data and returns train and test file names.\"\"\"\n",
    "    if train_data:\n",
    "        train_file_name = train_data\n",
    "    else:\n",
    "        train_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "        urllib.request.urlretrieve(\n",
    "            \"http://download.tensorflow.org/data/abalone_train.csv\",\n",
    "            train_file.name)\n",
    "        train_file_name = train_file.name\n",
    "        train_file.close()\n",
    "        print(\"Training data is downloaded to %s\" % train_file_name)\n",
    "\n",
    "    if test_data:\n",
    "        test_file_name = test_data\n",
    "    else:\n",
    "        test_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "        urllib.request.urlretrieve(\n",
    "            \"http://download.tensorflow.org/data/abalone_test.csv\", test_file.name)\n",
    "        test_file_name = test_file.name\n",
    "        test_file.close()\n",
    "        print(\"Test data is downloaded to %s\" % test_file_name)\n",
    "\n",
    "    if predict_data:\n",
    "        predict_file_name = predict_data\n",
    "    else:\n",
    "        predict_file = tempfile.NamedTemporaryFile(delete=False)\n",
    "        urllib.request.urlretrieve(\n",
    "            \"http://download.tensorflow.org/data/abalone_predict.csv\",\n",
    "            predict_file.name)\n",
    "        predict_file_name = predict_file.name\n",
    "        predict_file.close()\n",
    "        print(\"Prediction data is downloaded to %s\" % predict_file_name)\n",
    "\n",
    "    return train_file_name, test_file_name, predict_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiating an estimator\n",
    "# pre-made estimator\n",
    "my_nn = tf.estimator.DNNClassifier(feature_columns=[age, height, weight],\n",
    "                                   hidden_units=[10, 10, 10],\n",
    "                                   activation_fn=tf.nn.relu,\n",
    "                                   dropout=0.2,\n",
    "                                   n_classes=3,\n",
    "                                   optimizer=\"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom estimator\n",
    "nn = tf.estimator.Estimator(model_dn=model_fn,params=model_params)# 两个参数\n",
    "def model_fn(features, labels, mode, params):\n",
    "   # Logic to do the following:\n",
    "   # 1. Configure the model via TensorFlow operations\n",
    "   # 2. Define the loss function for training/evaluation\n",
    "   # 3. Define the training operation/optimizer\n",
    "   # 4. Generate predictions\n",
    "   # 5. Return predictions/loss/train_op/eval_metric_ops in EstimatorSpec object\n",
    "    return EstimatorSpec(mode, predictions, loss, train_op, eval_metric_ops)\n",
    "\n",
    "def my_input_fn():\n",
    "\n",
    "    # Preprocess your data here...\n",
    "\n",
    "    # ...then return 1) a mapping of feature columns to Tensors with\n",
    "    # the corresponding feature data, and 2) a Tensor containing labels\n",
    "    return feature_cols, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_fn接收三个参数：\n",
    "<ul>\n",
    "    <li><b>feature: </b> dict：包含特征，通过input_fn传递给model</li>\n",
    "    <li><b>labels: </b>Tensor：包含labels, 通过input_fn传递给model</li>\n",
    "    <li><b>mode: </b>tf.estimator.ModeKeys的string值代表会工作一下那个model_fn:</li>\n",
    "<p>\n",
    "    input_fn见最上面的说明\n",
    "</p>\n",
    "    <ul>\n",
    "        <li> tf.estimator.ModeKeys.TRAIN：model_fn执行training mode，通过train()调用</li>\n",
    "        <li> tf.estimator.ModeKeys.EVAL: model_fn执行evaluation mode,通过evaluate()调用</li>\n",
    "        <li> tf.estimator.ModeKeys.PREDICT: model_fn执行predict mode，通过predict()调用</li>\n",
    "    </ul>\n",
    "</ul>\n",
    "model_fn 也可以接收params参数（包含一个hyperparameters的字典），用来训练  \n",
    "函数的主体执行以下功能：\n",
    "<ul>\n",
    "    <li>配置模型:集模型的结构</li>\n",
    "    <li>定义损失函数</li>\n",
    "    <li>定义训练的操作，和optimizer的算法来让损失函数变小</li>\n",
    "</ul>\n",
    "<b>return:</b>  \n",
    "返回tf.estimator.EstimatorSpec 对象，包含以下值：  \n",
    "__new__(\n",
    "    cls,  \n",
    "    mode,  \n",
    "    predictions=None,  \n",
    "    loss=None,  \n",
    "    train_op=None,  \n",
    "    eval_metric_ops=None,  \n",
    "    export_outputs=None,  \n",
    "    training_chief_hooks=None,  \n",
    "    training_hooks=None,  \n",
    "    scaffold=None,  \n",
    "    evaluation_hooks=None  \n",
    ")\n",
    "<ul>\n",
    "    <li><b>mode(required) </b>这个model运行的mode，一般而言会在model_fn中返回mode参数</li>\n",
    "    <ul>\n",
    "        <li>For <b>mode == ModeKeys.TRAIN: </b>required fields are loss and train_op.</li>\n",
    "        <li>For <b>mode == ModeKeys.EVAL: </b>required field is loss.</li>\n",
    "        <li>For <b>mode == ModeKeys.PREDICT: </b>required fields are predictions.</li>\n",
    "    </ul>\n",
    "    <li><b>predictions(required in PREDICT model) </b>dict：将选择的名字于model预测值得Tensor匹配 \n",
    "        e.g. python predictions = {\"results\":tensor_of_predictions}  \n",
    "        PREDICT mode,在EstimatorSpec中得dict会通过predict()返回\n",
    "    </li>\n",
    "    <li><b>loss(required in EVAL and TRAIN mode) </b>A Tensor 包含一个标量损失值</li>\n",
    "    <li><b> train_op (required only in TRAIN mode) </b>An Op that runs one step of training.</li>\n",
    "    <li><b> eval_metric_ops (optional) </b>dict: name/value匹配特定得metrics可以被模型在EVAL模型中计算，name是选择得metric，value是计算结果，tf.metrics模块提供一些普遍的已经被定义好得函数  \n",
    "        e.g. 一下的评估中包含一个‘accuracy'的metric使用tf.metrics.accuracy计算：  \n",
    "      python eval_metric_ops = {'accuracy': tf.metrics.accuracy(labels,predictions)}  \n",
    "        如果不用这个参数，那么在evaluation的时候只有loss会被计算\n",
    "    </li>        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Configuring a neural network with tf.feature_column and tf.layers\n",
    "<b>model construction +predictions</b>  \n",
    "neural network构建包含三个部分：input layer, hidden layers和output layer  \n",
    "\n",
    "input layer：包含一些列的nodes接收feature data(通过features参数传递到model_fn中)当features包含n-dimension Tensor(所有的特征数据),那么这层就作为input layer。  \n",
    "features： dict of feature_columns，通过input function传递到model中，可以通过tf.feature_column.input_layer函数将其转换成input_layer Tensor。  \n",
    "e.g. : input_layer = tf.feature_column.input_layer(features=features,feature_columns=[age, height, weight])  \n",
    "input_layer()包含两个required参数：\n",
    "<ul>\n",
    "    <li><b>features </b>a mapping 从字符串keys到包含相对应的feature data Tensor。这就是传递到model_fn中的feature参数</li> \n",
    "    <li><b>feature_columns </b>a list 包含所有的模型中的FeatureColumns，例如以上例子中的age, height, weight</li>\n",
    "</ul>\n",
    "<p>\n",
    "    input layer通过activation function(对前一层输出的数据进行非线性转换)和hidden layers连接，hidden layer的最后一层连接到输出层，model的最后一层，tf.layers提供tf.layers.dense方程来构建全连接层。activation通过activation参数进行控制。activation其中一些选择有：\n",
    "    <ul>\n",
    "        <li><b>tf.nn.relu </b>e.g. 创建layer units nodes全连接到前一层的input_layer用relu：  \n",
    "            python hidden_layer= tf.layers.dense(inputs=input_layer,units=10,activation=tf.nn.relu)\n",
    "        </li>\n",
    "        <li><b>tf.nn.relu6 </b>计算方法：min(max(features, 0), 6)  \n",
    "            e.g. python second_hidden_layer = tf.layers.dense( inputs=hidden_layer, units=20, activation=tf.nn.relu)\n",
    "        </li>\n",
    "        <li><b>None </b> 不连接activate function，只有linear transformation  \n",
    "            python output_layer = tf.layers.dense( inputs=second_hidden_layer, units=3, activation=None)\n",
    "        </li>\n",
    "    </ul>\n",
    "其他可能选择：  \n",
    "output_layer = tf.layers.dense(inputs=second_hidden_layer,\n",
    "                               units=10,\n",
    "                               activation_fn=tf.sigmoid)  \n",
    "上面的code船舰了一个output_layer，通过一个sigmoid激活函数全连接到second_hidden_layer\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining loss for the model\n",
    "model_fn返回的EstimatorSpec必须要包含loss：a Tensor(表示loss值)  \n",
    "tf.losses模块提供convenience functions计算不同metrics中的loss：\n",
    "<ul>\n",
    "    <li><b>absolute_difference(labels, predictions) </b>计算loss用absolute-difference方程计算(L1 loss)</li>\n",
    "    <li><b>log_loss(labels, predictions) </b>计算loss用logistic loss formula计算(一般用logistic regression)</li>\n",
    "    <li><b>mean_squared_error(labels, predictions) </b>(MSE;用L2 loss)</li>\n",
    "</ul>\n",
    "以下例子中的model_fn用mean_squared_error()计算  \n",
    "<p>\n",
    "    补充的用来evaluation的metrics加到eval_metric_ops字典当中，以下code定义rmse metric，用来在model predictions时计算root mean sqaured error。labels tensor需要转换到float64来匹配predictions tensor的数据类型（包含实数）：  \n",
    "    eval_metric_ops = {\"rmse\":tf.metrics.root_mean_squared_error(  \n",
    "         tf.cast(lables,tf.float64),predictions))\n",
    "\n",
    "### Defining the training op for the model\n",
    "training op定义优化算法。一般而言，在训练的时候，目标是最小化loss。一个简单的来创建training op的方法是实例化tf.train.Optimizer的子类并且调用它的minimize方法\n",
    "<p>\n",
    "    以下用例当中learning_rate传送到function的param参数当中，使用gradient descent optimizer。对于global_step，采用convenience function tf.train.get_global_step来生成一个整数变量：  \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=params[\"learning_rate\"])  \n",
    "    training_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step())\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 完整的model_fn\n",
    "def model_fn(features,labels,mode,params):\n",
    "    \"\"\"Model function for Estimator.\"\"\"\n",
    "\n",
    "  # Connect the first hidden layer to input layer\n",
    "  # (features[\"x\"]) with relu activation\n",
    "    first_hidden_layer = tf.layer.dense(feature['x'],10,activation=tf.nn.relu)\n",
    "    \n",
    "    # Connect the second hidden layer to first hidden layer with relu\n",
    "    second_hidden_layer = tf.layers.dense(first_hidden_layer,10,activation=tf.nn.relu)\n",
    "    \n",
    "    # Connect the output layer to second hidden layer (no activation fn)\n",
    "    output_layer = tf.layers.dense(second_hidden_layer,1)\n",
    "    \n",
    "    # Reshape output layer to 1-dim Tensor to return predictions\n",
    "    predictions = tf.reshape(output_layer,[-1])\n",
    "    predictions_dict = {\"age\":predictions}\n",
    "    \n",
    "    # Calculate loss using mean squared error\n",
    "    loss = tf.losses.mean_squared_error(labels, predictions)\n",
    "    \n",
    "    # calculate root mean squared error as additional eval metric\n",
    "    eval_metric_ops = {\n",
    "        \"rmse\": tf.metrics.root_mean_squared_error(\n",
    "        tf.cast(labels, tf.float64), predictions)\n",
    "    }\n",
    "    \n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=param[\"learning_rate\"])\n",
    "    train_op = optimizer.minimize(loss=loss,global_step=tf.train_get_global_step())\n",
    "    \n",
    "    # Provide an estimator spec for `ModeKeys.EVAL` and `ModeKeys.TRAIN` modes.\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions = predictions\n",
    "        loss=loss,\n",
    "        train_op=train_op\n",
    "        eval_metric_ops=eval_metric_ops\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(unused_argv):\n",
    "  # Load datasets\n",
    "    abalone_train, abalone_test, abalone_predict = maybe_download(\n",
    "    FLAGS.train_data, FLAGS.test_data, FLAGS.predict_data)\n",
    "\n",
    "  # Training examples\n",
    "    training_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_train, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Test examples\n",
    "    test_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_test, target_dtype=np.int, features_dtype=np.float64)\n",
    "\n",
    "  # Set of 7 examples for which to predict abalone ages\n",
    "    prediction_set = tf.contrib.learn.datasets.base.load_csv_without_header(\n",
    "      filename=abalone_predict, target_dtype=np.int, features_dtype=np.float64)\n",
    "    \n",
    "    # Set model params\n",
    "    model_params = {\"learning_rate\": LEARNING_RATE}\n",
    "    \n",
    "    # Instantiate Estimator\n",
    "    nn = tf.estimator.Estimator(model_fn=model_fn,params=model_params)\n",
    "    \n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\":np.array(training_set.data)},\n",
    "        y=np.array(training_set.target),\n",
    "        num_epochs=None,\n",
    "        shuffle=True)\n",
    "    \n",
    "    # train\n",
    "    nn.train(input_fn=train_input_fn,steps=5000)\n",
    "    \n",
    "    # score_accuracy\n",
    "    test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\":np.array(test_set.data)},\n",
    "        y=np.array(test_set.target),\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    \n",
    "    ev = nn.evaluate(input_fn=test_input_fn)\n",
    "    print(\"Loss: %s\" % ev[\"loss\"])\n",
    "    print(\"Root Mean Squared Error: %s\" % ev[\"rmse\"])\n",
    "    \n",
    "    # print out predictions\n",
    "    predict_input_fn=tf.estimator.inputs.numpy_input_fn(\n",
    "        x={\"x\":prediction_set.data},\n",
    "        num_epochs=1,\n",
    "        shuffle=False)\n",
    "    predictions = nn.predict(input_fn=predict_input_fn)\n",
    "    for i, p in enumerate(predictions):\n",
    "        print(\"Prediction %s: %s\" % (i + 1, p[\"ages\"]))\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\n",
    "    parser.add_argument(\n",
    "      \"--train_data\", type=str, default=\"\", help=\"Path to the training data.\")\n",
    "    parser.add_argument(\n",
    "      \"--test_data\", type=str, default=\"\", help=\"Path to the test data.\")\n",
    "    parser.add_argument(\n",
    "      \"--predict_data\",\n",
    "      type=str,\n",
    "      default=\"\",\n",
    "      help=\"Path to the prediction data.\")\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
